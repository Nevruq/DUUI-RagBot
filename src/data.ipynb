{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f2d470c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349\n"
     ]
    }
   ],
   "source": [
    "import os   \n",
    "\n",
    "PATH_DUUI = \"data/duui-uima\"\n",
    "FILTER_FILES = {\".py\", \".ipynb\"}\n",
    "count = 0\n",
    "LIST_XML_FILES = []\n",
    "for root, subdirs, files in os.walk(PATH_DUUI):\n",
    "    for file in files:\n",
    "        current_file = os.path.join(root, file)\n",
    "        # filter files and ignore pom.xml\n",
    "        if (file.endswith(tuple(FILTER_FILES)) and (file != \"pom.xml\")):\n",
    "            LIST_XML_FILES.append(current_file)\n",
    "print(len(LIST_XML_FILES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a0a7b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d2c2e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!\"{sys.executable}\" -m pip install -U chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57c589e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: openai in /home/nev/Documents/Bachelor/DUUI-RagBot/venv/lib/python3.13/site-packages (2.14.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/nev/Documents/Bachelor/DUUI-RagBot/venv/lib/python3.13/site-packages (from openai) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/nev/Documents/Bachelor/DUUI-RagBot/venv/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/nev/Documents/Bachelor/DUUI-RagBot/venv/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/nev/Documents/Bachelor/DUUI-RagBot/venv/lib/python3.13/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/nev/Documents/Bachelor/DUUI-RagBot/venv/lib/python3.13/site-packages (from openai) (2.12.5)\n",
      "Requirement already satisfied: sniffio in /home/nev/Documents/Bachelor/DUUI-RagBot/venv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/nev/Documents/Bachelor/DUUI-RagBot/venv/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/nev/Documents/Bachelor/DUUI-RagBot/venv/lib/python3.13/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/nev/Documents/Bachelor/DUUI-RagBot/venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /home/nev/Documents/Bachelor/DUUI-RagBot/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/nev/Documents/Bachelor/DUUI-RagBot/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/nev/Documents/Bachelor/DUUI-RagBot/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/nev/Documents/Bachelor/DUUI-RagBot/venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/nev/Documents/Bachelor/DUUI-RagBot/venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/nev/Documents/Bachelor/DUUI-RagBot/venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f49570c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection created!\n"
     ]
    }
   ],
   "source": [
    "import chromadb as cdb\n",
    "\n",
    "client = cdb.PersistentClient(\"chroma\")\n",
    "client.delete_collection(name=\"DUUI_RAG_PYTHON\")\n",
    "collection = client.get_or_create_collection(name=\"DUUI_RAG_PYTHON\")\n",
    "print(\"Collection created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a68e3977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing multiple ways to Embed Code\n",
    "# Load model directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1eaca2b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▌                                                                                                                                            | 11/349 [00:09<06:19,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leerer eintrag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████████████████▏                                                                                                                      | 63/349 [00:52<03:26,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leerer eintrag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████████████████▊                                                                                                                     | 67/349 [00:53<01:50,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leerer eintrag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████████████████▏                                                                                                                 | 75/349 [00:59<02:45,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leerer eintrag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████████████████████▍                                                                                                           | 90/349 [01:16<05:42,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leerer eintrag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████████████████████                                                                                                          | 94/349 [01:17<02:33,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leerer eintrag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|████████████████████████████████████████████████████████████████████████████████████▌                                                           | 205/349 [01:45<00:38,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leerer eintrag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                        | 289/349 [02:42<02:29,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leerer eintrag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                 | 307/349 [02:56<00:22,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leerer eintrag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 349/349 [03:30<00:00,  1.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chunk the files with chunker\n",
    "\n",
    "from tqdm import tqdm\n",
    "import chunker\n",
    "import uuid\n",
    "\n",
    "\n",
    "# cast files to Chroma format\n",
    "\n",
    "count = 0\n",
    "for file in tqdm(LIST_XML_FILES):\n",
    "    chunks = chunker.chunk_python_file(file, include_header=True, include_methods=True)\n",
    "    ids, metas, docs = [], [], []\n",
    "    for chunk in chunks:\n",
    "        chroma_format = chunker.chunk_to_chroma_item(chunk.text, chunk.meta)\n",
    "        # some empty documents exist\n",
    "        if chroma_format[\"document\"] != \"\":           \n",
    "            ids.append(chroma_format[\"id\"])\n",
    "            metas.append(chroma_format[\"metadata\"])\n",
    "            docs.append(chroma_format[\"document\"])\n",
    "        else:\n",
    "            print(\"leerer eintrag\")\n",
    "    if ids:\n",
    "        collection.add(ids=ids, metadatas=metas, documents=docs)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89150ed2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OpenAI' from 'openai' (/home/nev/.local/lib/python3.10/site-packages/openai/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38066/1387569010.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpython_helper_api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m collection.query(query_texts= \"\"\"classifier = load_model(model_name)\n\u001b[1;32m      4\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhate_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         for c, res in enumerate(results):\"\"\", n_results=5)\n",
      "\u001b[0;32m~/Documents/Bachelor/DUUI-RagBot/src/python_helper_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This File generates with a given User Input a help / fix to a DUUI-question implemented in python?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mllm_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mRAG\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquery_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mMODEL_NAME_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gpt-5-nano-2025-08-07\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Bachelor/DUUI-RagBot/src/llm_wrapper.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdotenv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dotenv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchromadb\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcbd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (/home/nev/.local/lib/python3.10/site-packages/openai/__init__.py)"
     ]
    }
   ],
   "source": [
    "import python_helper_api\n",
    "\n",
    "collection.query(query_texts= \"\"\"classifier = load_model(model_name)\n",
    "        results = classifier.hate_prediction(texts)\n",
    "        for c, res in enumerate(results):\"\"\", n_results=5)\n",
    "\n",
    "print(python_helper_api.python_fix_code(\"Wie ist das DUUI-Hate-API im duui_hate.py aufgebaut (Endpoints /v1/process, /v1/typesystem, Request/Response-Modelle) und wie rufe ich es mit einem Beispiel-Request an?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4a4345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
